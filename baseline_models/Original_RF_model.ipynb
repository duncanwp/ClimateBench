{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt  # Python standard library datetime  module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from eofs.xarray import Eof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**parameters & hyperparameters\n",
    "\n",
    "RSCV = True\n",
    "path_output='output_path/output.nc'\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! wget https://zenodo.org/record/5465895/files/train_val.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract data into your \"local\" drive on Google\n",
    "#! tar -xvf train_val.tar.gz\n",
    "## Check all files in your local environment\n",
    "#print(\"============== Files =============\")\n",
    "#! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities for normalizing the emissions data\n",
    "min_co2 = 0.\n",
    "max_co2 = 2400\n",
    "def normalize_co2(data):\n",
    "    return data / max_co2\n",
    "\n",
    "def un_normalize_co2(data):\n",
    "    return data * max_co2\n",
    "\n",
    "min_ch4 = 0.\n",
    "max_ch4 = 0.6\n",
    "def normalize_ch4(data):\n",
    "    return data / max_ch4\n",
    "\n",
    "def un_normalize_ch4(data):\n",
    "    return data * max_ch4\n",
    "\n",
    "data_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "inputs = glob(data_path + \"inputs_s*.nc\")\n",
    "SECONDS_IN_YEAR = 60*60*24*365 #s\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
    "\n",
    "for input in inputs:\n",
    "    label=input.split('_')[1][:-3]\n",
    "    X = xr.open_dataset(input)\n",
    "    x = range(2015, 2101)\n",
    "\n",
    "    weights = np.cos(np.deg2rad(X.latitude))\n",
    "    \n",
    "    axes[0, 0].plot(x, X['CO2'].data, label=label)\n",
    "    axes[0, 0].set_ylabel(\"Cumulative anthropogenic CO2 \\nemissions since 1850 (GtCO2)\")\n",
    "    axes[0, 1].plot(x, X['CH4'].data, label=label)\n",
    "    axes[0, 1].set_ylabel(\"Anthropogenic CH4 \\nemissions (GtCH4 / year)\")\n",
    "    # FIXME: Not sure where this factor of 1000 comes from...! Maybe the CEDS data is really g/m-2/s?\n",
    "    axes[1, 0].plot(x, X['SO2'].weighted(weights).sum(['latitude', 'longitude']).data*SECONDS_IN_YEAR*1e-9, label=label)\n",
    "    axes[1, 0].set_ylabel(\"Anthropogenic SO2 \\nemissions (GtSO2 / year)\")\n",
    "    axes[1, 1].plot(x, X['BC'].weighted(weights).sum(['latitude', 'longitude']).data*SECONDS_IN_YEAR*1e-9, label=label)\n",
    "    axes[1, 1].set_ylabel(\"Anthropogenic BC \\nemissions (GtBC / year)\")\n",
    "\n",
    "axes[0, 0].set_title('CO2')\n",
    "axes[0, 1].set_title('CH4')\n",
    "axes[1, 0].set_title('SO2')\n",
    "axes[1, 1].set_title('BC')\n",
    "axes[0, 0].legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "test_data_path='/test-data/inputs_ssp245-2.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one combined historical + ssp585 + ssp126 + ssp370 timeseries for now\n",
    "X = xr.concat([xr.open_dataset(data_path + 'inputs_historical.nc'), xr.open_dataset(data_path + 'inputs_ssp585.nc'),xr.open_dataset(data_path+ 'inputs_ssp126.nc'),xr.open_dataset(data_path+ 'inputs_ssp370.nc'),xr.open_dataset(data_path+ 'inputs_hist-aer.nc'),xr.open_dataset(data_path+ 'inputs_hist-GHG.nc')], dim='time').compute()\n",
    "\n",
    "# Take the average member for the historical, ssp585, ssp126, ssp370, hist-aer, hist-ghg\n",
    "Y = xr.concat([xr.open_dataset(data_path + 'outputs_historical.nc').mean(dim=\"member\"), xr.open_dataset(data_path + 'outputs_ssp585.nc').mean(dim=\"member\"),xr.open_dataset(data_path+ 'outputs_ssp126.nc').mean(dim=\"member\"),xr.open_dataset(data_path+ 'outputs_ssp370.nc').mean(dim=\"member\"),xr.open_dataset(data_path+ 'outputs_hist-aer.nc').mean(dim=\"member\"),xr.open_dataset(data_path+ 'outputs_hist-GHG.nc').mean(dim=\"member\")], dim='time').compute()\n",
    "\n",
    "\n",
    "# Convert the precip values to mm/day\n",
    "Y[\"pr\"] *= 86400\n",
    "Y[\"pr90\"] *= 86400\n",
    "\n",
    "X[\"time\"]=np.arange(1, 424 + 165 + 165) ## 165+86+86+86+65+165+1\n",
    "Y[\"time\"]=np.arange(1, 424 + 165 + 165)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## proj = ccrs.PlateCarree()\n",
    "#fig = plt.figure(figsize=(18, 8))\n",
    "#plt.subplot(221)\n",
    "#np.log(X[\"SO2\"].sel(time=1850)).plot(vmin=-27, vmax=-20)\n",
    "## plt.gca().coastlines()\n",
    "#plt.gca().set_title('1850')\n",
    "#\n",
    "#plt.subplot(222)\n",
    "#np.log(X[\"SO2\"].sel(time=1970)).plot(vmin=-27, vmax=-20)\n",
    "## plt.gca().coastlines()\n",
    "#plt.gca().set_title('1970')\n",
    "#\n",
    "#plt.subplot(223)\n",
    "#np.log(X[\"SO2\"].sel(time=2020)).plot(vmin=-27, vmax=-20)\n",
    "## plt.gca().coastlines()\n",
    "#plt.gca().set_title('2020')\n",
    "#\n",
    "#plt.subplot(224)\n",
    "#m=np.log(X[\"SO2\"].sel(time=2100)).plot(vmin=-27, vmax=-20)\n",
    "## plt.gca().coastlines()\n",
    "#plt.gca().set_title('2100')\n",
    "#\n",
    "#fig.subplots_adjust(right=0.8)\n",
    "#cbar_ax = fig.add_axes([0.85, 0.15, 0.02, 0.7])\n",
    "#cbar = fig.colorbar(m, cax=cbar_ax)\n",
    "#cbar.set_label('Log anthropogenic SO2 emissions (log kg / m2 / s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(12, 8))\n",
    "#plt.subplot(221)\n",
    "#Y[\"tas\"].sel(time=2100).plot(vmin=0, cmap='Reds')\n",
    "#plt.gca().set_title('Annual Mean')\n",
    "#\n",
    "#plt.subplot(222)\n",
    "#Y[\"diurnal_temperature_range\"].sel(time=2100).plot(vmin=-4, vmax=4, cmap='RdBu_r' )\n",
    "#plt.gca().set_title('Mean diurnal range')\n",
    "#\n",
    "#plt.subplot(223)\n",
    "##  Convert precip to mm/day\n",
    "#Y[\"pr\"].sel(time=2100).plot(vmin=-5, vmax=5, cmap='RdBu_r')\n",
    "#plt.gca().set_title('Annual Mean')\n",
    "#\n",
    "#plt.subplot(224)\n",
    "#Y[\"pr90\"].sel(time=2100).plot(vmin=-5, vmax=5, cmap='RdBu_r')\n",
    "#plt.gca().set_title('Annual 90th percentile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "# latitude weights are applied before the computation of EOFs.\n",
    "bc_solver = Eof(X['BC'])\n",
    "\n",
    "# Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "# PC time series and the input SST anomalies at each grid point, and the\n",
    "# leading PC time series itself.\n",
    "bc_eofs = bc_solver.eofsAsCorrelation(neofs=5)\n",
    "bc_pcs = bc_solver.pcs(npcs=5, pcscaling=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an EOF solver to do the EOF analysis. Square-root of cosine of\n",
    "# latitude weights are applied before the computation of EOFs.\n",
    "so2_solver = Eof(X['SO2'])\n",
    "\n",
    "# Retrieve the leading EOF, expressed as the correlation between the leading\n",
    "# PC time series and the input SST anomalies at each grid point, and the\n",
    "# leading PC time series itself.\n",
    "so2_eofs = so2_solver.eofsAsCorrelation(neofs=5)\n",
    "so2_pcs = so2_solver.pcs(npcs=5, pcscaling=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Principle Components of the aerosol emissions (calculated above) in to Pandas DataFrames\n",
    "bc_df = bc_pcs.to_dataframe().unstack('mode')\n",
    "bc_df.columns = [f\"BC_{i}\" for i in range(5)]\n",
    "\n",
    "so2_df = so2_pcs.to_dataframe().unstack('mode')\n",
    "so2_df.columns = [f\"SO2_{i}\" for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring the emissions data back together again and normalise\n",
    "leading_historical_inputs = pd.DataFrame({\n",
    "    \"CO2\": normalize_co2(X[\"CO2\"].data),\n",
    "    \"CH4\": normalize_ch4(X[\"CH4\"].data)\n",
    "}, index=X[\"CO2\"].coords['time'].data)\n",
    "\n",
    "# Combine with aerosol EOFs\n",
    "leading_historical_inputs=pd.concat([leading_historical_inputs, bc_df, so2_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(truth, pred):\n",
    "    weights = np.cos(np.deg2rad(truth.lat))\n",
    "    return np.sqrt(((truth-pred)**2).weighted(weights).mean(['lat', 'lon'])).data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_inp_tas=Y[\"tas\"].stack(dim=[\"lat\", \"lon\"])\n",
    "y_inp_pr=Y[\"pr\"].stack(dim=[\"lat\", \"lon\"])\n",
    "y_inp_pr90=Y[\"pr90\"].stack(dim=[\"lat\", \"lon\"])\n",
    "y_inp_dtr=Y[\"diurnal_temperature_range\"].stack(dim=[\"lat\", \"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_input_tas = pd.DataFrame(y_inp_tas.to_pandas())\n",
    "df_y_input_pr = pd.DataFrame(y_inp_pr.to_pandas())\n",
    "df_y_input_pr90 = pd.DataFrame(y_inp_pr90.to_pandas())\n",
    "df_y_input_dtr = pd.DataFrame(y_inp_dtr.to_pandas())\n",
    "\n",
    "Xy_train_tas_ = pd.concat([leading_historical_inputs, df_y_input_tas], axis=1)\n",
    "Xy_train_pr_ = pd.concat([leading_historical_inputs, df_y_input_pr], axis=1)\n",
    "Xy_train_pr90_ = pd.concat([leading_historical_inputs, df_y_input_pr90], axis=1)\n",
    "Xy_train_dtr_ = pd.concat([leading_historical_inputs, df_y_input_dtr], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_train_tas = Xy_train_tas_.to_numpy()\n",
    "Xy_train_pr = Xy_train_pr_.to_numpy()\n",
    "Xy_train_pr90 = Xy_train_pr90_.to_numpy()\n",
    "Xy_train_dtr = Xy_train_dtr_.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inp=leading_historical_inputs.shape[1]\n",
    "n_iout=Xy_train_tas_.shape[1]\n",
    "\n",
    "X_train_tas=Xy_train_tas[:,0:n_inp]\n",
    "y_train_tas=Xy_train_tas[:,n_inp:n_iout]\n",
    "\n",
    "X_train_pr=Xy_train_pr[:,0:n_inp]\n",
    "y_train_pr=Xy_train_pr[:,n_inp:n_iout]\n",
    "\n",
    "X_train_pr90=Xy_train_pr90[:,0:n_inp]\n",
    "y_train_pr90=Xy_train_pr90[:,n_inp:n_iout]\n",
    "\n",
    "X_train_dtr=Xy_train_dtr[:,0:n_inp]\n",
    "y_train_dtr=Xy_train_dtr[:,n_inp:n_iout]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "reg1 = RandomForestRegressor(random_state=0)\n",
    "reg2 = RandomForestRegressor(random_state=0)\n",
    "reg3 = RandomForestRegressor(random_state=0)\n",
    "\n",
    "if(RSCV==False):\n",
    "    rf_tas = reg0.fit(X_train_tas,y_train_tas)\n",
    "    rf_pr = reg1.fit(X_train_pr,y_train_pr)\n",
    "    rf_pr90 = reg2.fit(X_train_pr90,y_train_pr90)\n",
    "    rf_dtr = reg3.fit(X_train_dtr,y_train_dtr)\n",
    "else:\n",
    "    rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random1 = RandomizedSearchCV(estimator = reg1, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random2 = RandomizedSearchCV(estimator = reg2, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "    rf_random3 = RandomizedSearchCV(estimator = reg3, param_distributions = random_grid, n_iter = 29, cv = 3, verbose=2, n_jobs = -1)\n",
    "\n",
    "    #n_iter = 29\n",
    "    \n",
    "    rf_tas = rf_random0.fit(X_train_tas,y_train_tas)\n",
    "    rf_pr = rf_random1.fit(X_train_pr,y_train_pr)\n",
    "    rf_pr90 = rf_random2.fit(X_train_pr90,y_train_pr90)\n",
    "    rf_dtr = rf_random3.fit(X_train_dtr,y_train_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if(RSCV==True):\n",
    "    print(rf_tas.best_params_)\n",
    "    print(rf_pr.best_params_)\n",
    "    print(rf_pr90.best_params_)\n",
    "    print(rf_dtr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test on SSP245\n",
    "\n",
    "test_Y = xr.open_dataset(data_path + 'test-data/outputs_ssp245_solution.nc').compute()\n",
    "test_X = xr.open_dataset(data_path + 'test-data/inputs_ssp245-2.nc').compute()\n",
    "\n",
    "tas_truth = test_Y[\"tas\"].mean('member')\n",
    "pr_truth = test_Y[\"pr\"].mean('member') * 86400\n",
    "pr90_truth = test_Y[\"pr90\"].mean('member') * 86400\n",
    "dtr_truth = test_Y[\"diurnal_temperature_range\"].mean('member')\n",
    "\n",
    "test_inputs = pd.DataFrame({\n",
    "    \"CO2\": normalize_co2(test_X[\"CO2\"].data),\n",
    "    \"CH4\": normalize_ch4(test_X[\"CH4\"].data)\n",
    "}, index=test_X[\"CO2\"].coords['time'].data)\n",
    "\n",
    "### Combine with aerosol EOFs\n",
    "test_inputs=pd.concat([test_inputs, \n",
    "                       bc_solver.projectField(test_X[\"BC\"], neofs=5, eofscaling=1).to_dataframe().unstack('mode').rename(columns={i:f\"BC_{i}\" for i in range(5)}),\n",
    "                       so2_solver.projectField(test_X[\"SO2\"], neofs=5, eofscaling=1).to_dataframe().unstack('mode').rename(columns={i:f\"_{i}\" for i in range(5)}),\n",
    "                       ], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_out_t = rf_tas.predict(test_inputs)\n",
    "m_out_p = rf_pr.predict(test_inputs)\n",
    "m_out_p90 = rf_pr90.predict(test_inputs)\n",
    "m_out_d = rf_dtr.predict(test_inputs)\n",
    "\n",
    "m_out_tas = m_out_t.reshape(86, 96, 144)\n",
    "m_out_pr = m_out_p.reshape(86, 96, 144)\n",
    "m_out_pr90 = m_out_p90.reshape(86, 96, 144)\n",
    "m_out_dtr = m_out_d.reshape(86, 96, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xr_output['pr'].sel(time=2015).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m_tas.sel(sample=35).plot(cmap=\"coolwarm\", norm=divnorm,\n",
    "#                          cbar_kwargs={\"label\":\"Temperature change / K\"})\n",
    "#plt.gca().set_title(\"Emulated 2050\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_output=xr.Dataset(coords={'time': test_X.time.values, 'lat': test_X.latitude.values, 'lon': test_X.longitude.values})\n",
    "xr_output[\"tas\"]=(['time', 'lat', 'lon'],  m_out_tas)\n",
    "xr_output[\"diurnal_temperature_range\"]=(['time', 'lat', 'lon'],  m_out_dtr)\n",
    "xr_output[\"pr\"]=(['time', 'lat', 'lon'],  m_out_pr)\n",
    "xr_output[\"pr90\"]=(['time', 'lat', 'lon'],  m_out_pr90)\n",
    "    \n",
    "#save output to netcdf \n",
    "xr_output.to_netcdf(path_output,'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coords={'lon': (['x', 'y'], lon),\n",
    "#                    'lat': (['x', 'y'], lat),\n",
    "#                    'time': pd.date_range('2014-09-06', periods=3)})\n",
    "#temp=np.array([[25, 24, 20, -12],[23, 21, 22, -11]])\n",
    "#xr_output[\"Temperature\"]=(['x', 'y', 'time'],  temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"RMSE: {get_rmse(tas_truth[35], m_out_tas[35])}\")\n",
    "print(f\"RMSE: {get_rmse(tas_truth[85], m_out_tas[85])}\")\n",
    "print(f\"RMSE: {get_rmse(tas_truth[30:40], m_out_tas[30:40])}\")\n",
    "print(f\"RMSE: {get_rmse(tas_truth[75:], m_out_tas[75:])}\")\n",
    "print(f\"RMSE: {get_rmse(tas_truth[35:], m_out_tas[35:])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"RMSE: {get_rmse(dtr_truth[35], m_out_dtr[35])}\")\n",
    "print(f\"RMSE: {get_rmse(dtr_truth[85], m_out_dtr[85])}\")\n",
    "print(f\"RMSE: {get_rmse(dtr_truth[30:40], m_out_dtr[30:40])}\")\n",
    "print(f\"RMSE: {get_rmse(dtr_truth[75:], m_out_dtr[75:])}\")\n",
    "print(f\"RMSE: {get_rmse(dtr_truth[35:], m_out_dtr[35:])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"RMSE: {get_rmse(pr_truth[35], m_out_pr[35])}\")\n",
    "print(f\"RMSE: {get_rmse(pr_truth[85], m_out_pr[85])}\")\n",
    "print(f\"RMSE: {get_rmse(pr_truth[30:40], m_out_pr[30:40])}\")\n",
    "print(f\"RMSE: {get_rmse(pr_truth[75:], m_out_pr[75:])}\")\n",
    "print(f\"RMSE: {get_rmse(pr_truth[35:], m_out_pr[35:])}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(f\"RMSE: {get_rmse(pr90_truth[35], m_out_pr90[35])}\")\n",
    "print(f\"RMSE: {get_rmse(pr90_truth[85], m_out_pr90[85])}\")\n",
    "print(f\"RMSE: {get_rmse(pr90_truth[30:40], m_out_pr90[30:40])}\")\n",
    "print(f\"RMSE: {get_rmse(pr90_truth[75:], m_out_pr90[75:])}\")\n",
    "print(f\"RMSE: {get_rmse(pr90_truth[35:], m_out_pr90[35:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict avg last 20 years\n",
    "\n",
    "m_out_t = rf_tas.predict(test_inputs[-20:].mean().values.reshape(1,12))\n",
    "m_out_p = rf_pr.predict(test_inputs[-20:].mean().values.reshape(1,12))\n",
    "m_out_p90 = rf_pr90.predict(test_inputs[-20:].mean().values.reshape(1,12))\n",
    "m_out_d = rf_dtr.predict(test_inputs[-20:].mean().values.reshape(1,12))\n",
    "\n",
    "m_out_tas = m_out_t.reshape(96, 144)\n",
    "m_out_pr = m_out_p.reshape(96, 144)\n",
    "m_out_pr90 = m_out_p90.reshape(96, 144)\n",
    "m_out_dtr = m_out_d.reshape(96, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_truth2=tas_truth[-20:].mean(dim=\"time\")\n",
    "pr_truth2=pr_truth[-20:].mean(dim=\"time\")\n",
    "pr90_truth2=pr90_truth[-20:].mean(dim=\"time\")\n",
    "dtr_truth2=dtr_truth[-20:].mean(dim=\"time\")\n",
    "\n",
    "print(f\"RMSE: {get_rmse(tas_truth2, m_out_tas)}\")\n",
    "print(f\"RMSE: {get_rmse(dtr_truth2, m_out_dtr)}\")\n",
    "print(f\"RMSE: {get_rmse(pr_truth2, m_out_pr)}\")\n",
    "print(f\"RMSE: {get_rmse(pr90_truth2, m_out_pr90)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (based on the module python3/2022.01)",
   "language": "python",
   "name": "python3_2022_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
